{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8249229f",
      "metadata": {
        "id": "8249229f",
        "outputId": "ca596171-fb4b-43e6-e868-9743425fe762",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required packages (if needed)\n",
        "%pip install -q torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c4364355",
      "metadata": {
        "id": "c4364355",
        "outputId": "22e912e2-d858-4cf9-bfe6-2157f8c1900c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Basic setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "233dddab",
      "metadata": {
        "id": "233dddab",
        "outputId": "ccc0ad8c-3adf-410d-883d-195faac9a7c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:00<00:00, 17.2MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 489kB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:00<00:00, 3.87MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 7.21MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Transform: Normalize images to [0, 1] and flatten them\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Standard MNIST normalization\n",
        "])\n",
        "\n",
        "# Download and load data\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# For speed: use a smaller subset\n",
        "train_dataset, _ = random_split(train_dataset, [10000, len(train_dataset) - 10000])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get a batch of images\n",
        "examples = next(iter(train_loader))\n",
        "images, labels = examples\n",
        "\n",
        "# Plot the first 6 images\n",
        "plt.figure(figsize=(10, 2))\n",
        "for i in range(7):\n",
        "    plt.subplot(1, 7, i + 1)\n",
        "    plt.imshow(images[i][0], cmap=\"gray\")\n",
        "    plt.title(f\"Label: {labels[i].item()}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4sabVOeMHLOe",
        "outputId": "15b6a222-4d9e-4bfe-e9f9-8d0077f9f1fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "id": "4sabVOeMHLOe",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teacher: bigger model\n",
        "class TeacherNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 1200)\n",
        "        self.fc2 = nn.Linear(1200, 600)\n",
        "        self.fc3 = nn.Linear(600, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "# Student: smaller model\n",
        "class StudentNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 300)\n",
        "        self.fc2 = nn.Linear(300, 100)\n",
        "        self.fc3 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ],
      "metadata": {
        "id": "Vx4ENOxCHdVy"
      },
      "id": "Vx4ENOxCHdVy",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_teacher(model, train_loader, epochs=5, lr=1e-3):\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x)\n",
        "            loss = criterion(output, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
        "    return model\n",
        "\n",
        "# Instantiate and train teacher\n",
        "teacher_model = TeacherNet()\n",
        "teacher_model = train_teacher(teacher_model, train_loader)"
      ],
      "metadata": {
        "id": "t9r2CJRdHov4",
        "outputId": "63c4918f-2ee2-4d5e-9bd8-28daa6c2dda5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "t9r2CJRdHov4",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 62.8367\n",
            "Epoch 2/5, Loss: 23.4720\n",
            "Epoch 3/5, Loss: 16.1862\n",
            "Epoch 4/5, Loss: 11.2762\n",
            "Epoch 5/5, Loss: 8.4171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            pred = logits.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    acc = 100.0 * correct / total\n",
        "    print(f\"Accuracy: {acc:.2f}%\")\n",
        "    return acc\n",
        "\n",
        "# Evaluate teacher model\n",
        "evaluate(teacher_model, test_loader)"
      ],
      "metadata": {
        "id": "1fCpkl39H3h2",
        "outputId": "4b732763-44f3-4933-ebb5-7850cac1a393",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1fCpkl39H3h2",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.35%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95.35"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_student_hard(student_model, train_loader, epochs=5, lr=1e-3):\n",
        "    student_model.to(device)\n",
        "    optimizer = optim.Adam(student_model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    student_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = student_model(x)\n",
        "            loss = criterion(output, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
        "    return student_model\n",
        "\n",
        "# Train the student model (hard labels only)\n",
        "student_hard = StudentNet()\n",
        "student_hard = train_student_hard(student_hard, train_loader)"
      ],
      "metadata": {
        "id": "wWk-bhmpH8Km",
        "outputId": "56018000-a351-4d2e-c445-1eddd2dd257f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wWk-bhmpH8Km",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 82.2910\n",
            "Epoch 2/5, Loss: 34.8895\n",
            "Epoch 3/5, Loss: 22.3143\n",
            "Epoch 4/5, Loss: 15.4817\n",
            "Epoch 5/5, Loss: 9.4693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate student trained on hard labels\n",
        "evaluate(student_hard, test_loader)"
      ],
      "metadata": {
        "id": "kLfh4rZjIC27",
        "outputId": "762b0196-64a2-4d4d-c0e7-95748e10b48a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kLfh4rZjIC27",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.45%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95.45"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def distillation_loss(student_logits, teacher_logits, temperature):\n",
        "    \"\"\"\n",
        "    Computes the soft loss: KL Divergence between teacher and student logits.\n",
        "    \"\"\"\n",
        "    T = temperature\n",
        "    student_probs = F.log_softmax(student_logits / T, dim=1)\n",
        "    teacher_probs = F.softmax(teacher_logits / T, dim=1)\n",
        "    return F.kl_div(student_probs, teacher_probs, reduction=\"batchmean\") * (T ** 2)\n",
        "\n",
        "def train_student_distilled(student_model, teacher_model, train_loader, epochs=5, lr=1e-3, temperature=5.0, alpha=0.5):\n",
        "    student_model.to(device)\n",
        "    teacher_model.to(device)\n",
        "    teacher_model.eval()\n",
        "\n",
        "    optimizer = optim.Adam(student_model.parameters(), lr=lr)\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    student_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher_model(x)\n",
        "\n",
        "            student_logits = student_model(x)\n",
        "\n",
        "            loss_soft = distillation_loss(student_logits, teacher_logits, temperature)\n",
        "            loss_hard = ce_loss(student_logits, y)\n",
        "\n",
        "            loss = alpha * loss_soft + (1 - alpha) * loss_hard\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Distilled Loss: {total_loss:.4f}\")\n",
        "\n",
        "    return student_model\n",
        "\n",
        "# Train student with distillation\n",
        "student_distilled = StudentNet()\n",
        "student_distilled = train_student_distilled(student_distilled, teacher_model, train_loader)"
      ],
      "metadata": {
        "id": "ZeYVoxArIKZB",
        "outputId": "6fc6915c-8319-4fd3-b242-2362e7de01b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZeYVoxArIKZB",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Distilled Loss: 553.7055\n",
            "Epoch 2/5, Distilled Loss: 131.1812\n",
            "Epoch 3/5, Distilled Loss: 65.5557\n",
            "Epoch 4/5, Distilled Loss: 42.6676\n",
            "Epoch 5/5, Distilled Loss: 28.3162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate student trained with distillation\n",
        "evaluate(student_distilled, test_loader)"
      ],
      "metadata": {
        "id": "XANbI1GxIRCU",
        "outputId": "c74117ad-9ca9-4265-ba8b-d884bc3081b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XANbI1GxIRCU",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.97%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.97"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Teacher params:  {count_params(teacher_model):,}\")\n",
        "print(f\"Student (hard) params:  {count_params(student_hard):,}\")\n",
        "print(f\"Student (distilled) params:  {count_params(student_distilled):,}\")"
      ],
      "metadata": {
        "id": "ntfRdlFvIXD9",
        "outputId": "d9f3a65e-57bc-4bcb-c88e-2a34ebb5e379",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ntfRdlFvIXD9",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher params:  1,668,610\n",
            "Student (hard) params:  266,610\n",
            "Student (distilled) params:  266,610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß™ Knowledge Distillation on MNIST: Hands-on Demo\n",
        "\n",
        "This notebook demonstrates **Knowledge Distillation**, a technique to train a smaller neural network (student) by learning from a larger, well-trained model (teacher).\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Objective\n",
        "\n",
        "- Compare three models on the MNIST digit classification task:\n",
        "  - A **Teacher** model (large)\n",
        "  - A **Student** trained with **hard labels** (baseline)\n",
        "  - A **Student** trained via **Knowledge Distillation** (soft labels)\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Experiment Setup\n",
        "\n",
        "- Dataset: 10k samples from MNIST (for speed)\n",
        "- Input: 28√ó28 grayscale digit images\n",
        "- Framework: PyTorch\n",
        "\n",
        "### Models:\n",
        "\n",
        "| Model   | Architecture | Param Count |\n",
        "|---------|--------------|-------------|\n",
        "| Teacher | 784 ‚Üí 1200 ‚Üí 600 ‚Üí 10 | 1.67M |\n",
        "| Student | 784 ‚Üí 300 ‚Üí 100 ‚Üí 10 | 266k |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Training Overview\n",
        "\n",
        "- **Teacher**: Trained on ground truth with CrossEntropyLoss\n",
        "- **Hard-label Student**: Same loss, smaller model\n",
        "- **Distilled Student**:\n",
        "  - Trained on a **blend of soft labels (KL-Divergence)** and hard labels\n",
        "  - Temperature = 5.0\n",
        "  - Alpha (soft/hard loss mix) = 0.5\n",
        "\n",
        "---\n",
        "\n",
        "## üìà Results\n",
        "\n",
        "| Model                | Params     | Accuracy  |\n",
        "|---------------------|------------|-----------|\n",
        "| **Teacher**          | 1,668,610  | **95.35%** |\n",
        "| **Student (hard)**   | 266,610    | **95.45%** |\n",
        "| **Student (distilled)** | 266,610    | **94.97%** |\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Observations\n",
        "\n",
        "- The **student (hard)** surprisingly matched or slightly outperformed the teacher.\n",
        "- The **distilled student** performed slightly worse, possibly due to:\n",
        "  - Small dataset\n",
        "  - Suboptimal temperature or alpha\n",
        "- Distillation gains are more pronounced on complex tasks or larger datasets.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Key Learnings\n",
        "\n",
        "- Distillation transfers *soft knowledge* ‚Äî not just correct answers, but *probabilities over alternatives*.\n",
        "- Works best when:\n",
        "  - Teacher is significantly stronger than student\n",
        "  - Task is complex enough to benefit from richer supervision\n",
        "- A distilled model retains teacher-like performance while being lightweight.\n"
      ],
      "metadata": {
        "id": "mvXlnuWrI44E"
      },
      "id": "mvXlnuWrI44E"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZGl9KEhI5bE"
      },
      "id": "JZGl9KEhI5bE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}